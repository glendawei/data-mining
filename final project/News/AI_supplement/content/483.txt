Nvidia CEO: We bet the farm on AI and no one knew it Nvidia founder and CEO Jensen Huang said today that the company made an existential business decision in 2018 that few realized would redefine its future and help redefine an evolving industry. It’s paid off enormously, of course, but Huang said this is only the beginning of an AI-powered near future — a future powered primarily by Nvidia hardware. Was this successful gambit lucky or smart? The answer, it seems, is “yes.” He made these remarks and reflections during a keynote at SIGGRAPH in Los Angeles. That watershed moment five years ago, Huang said, was the choice to embrace AI-powered image processing in the form of ray tracing and intelligent upscaling: RTX and DLSS, respectively. (Quotes are from my notes and may not be verbatim, some minor corrections may take place after checking the transcript.) “We realized rasterization was reaching its limits,” he said, referring to the traditional, widely used method of rendering a 3D scene. “2018 was a ‘bet the company’ moment. It required that we reinvent the hardware, the software, the algorithms. And while we were reinventing CG with AI, we were reinventing the GPU for AI.” While ray-tracing and DLSS are still in the process of being adopted across the diverse and complex world of consumer GPUs and gaming, the architecture that they had created to enable it was found to be a perfect partner for the growing machine learning development community. The massive amount of calculation required to train larger and larger generative models was served best not by traditional datacenters with some GPU capability, but systems like the H100 designed from the start to perform the necessary operations at scale. It would be fair to say that AI development was in some ways only limited by the availability of these computing resources. Nvidia was in possession of a Beanie Baby-scale boom and has sold about as many servers and workstations as it has been able to make. But Huang asserted that this has just been the beginning. The new models not only need to be trained, but run in real time by millions, perhaps billions of users on a regular basis. “The future is an LLM at the front of just about everything: “Human” is the new programming language,” he said. Everything from visual effects to a rapidly digitizing manufacturing market, factory design, and heavy industry will adopt in some degree a natural language interface, Huang hazarded. “Entire factories will be software-defined and robotic, and the cars they’ll be building will themselves be robotic. So it’s robotically designed robots building robots,” he said. Some may not share his outlook, which while plausible also happens to be extremely friendly to Nvidia’s interests. But while the degree of reliance on LLMs may be unknown, few would say it will not be adopted at all, and even a conservative estimate of who will use it and for what will necessitate a serious investment in new computing resources. Investing millions of dollars in last-generation computing resources, like CPU-focused racks, is foolish when something like a GH200, the newly revealed and datacenter-dedicated AI development hardware, can do the same job for less than a tenth of the cost and power requirements. He gleefully presented a video showing a LEGO-like assembly of multiple Grace Hopper computing units into a blade, then a rack, then a row of GH200s all connected at such high speeds that they amounted to “the world’s largest single GPU,” comprising one full exaflop of ML-specialty computing power. Image Credits: Devin Coldewey Image Credits: Devin Coldewey “This is real size, by the way,” he said, standing for dramatic effect at the center of the visualization. “And it probably even runs Crysis.” These are going to be the basic unit of the digital, AI-dominated industry of the future, he proposed. “I don’t know who said it, but… the more you buy, the more you save. If I could ask you to remember one thing from my talk today, that would be it,” he said, earning a laugh from the game audience here at SIGGRAPH. No mention of AI’s many challenges, regulation, or the entire concept of AI shifting — as it already has multiple times in the last year. It’s a rose-tinted view of the world, to be sure, but when you’re selling pickaxes and shovels during a gold rush, you can afford to think that way. 