Sam Altmanâ€™s big European tour Fresh from telling U.S. lawmakers heâ€™s a fan of regulation and laws are needed to mitigate the risks around artificial intelligence â€” and, indeed, calling for an international regulatory body for AI â€” OpenAI CEOâ€™s Sam Altman is on a tour of Europe this week to meet regulators and warn against, er, too much regulation of AI. This is a familiar dance. Big Tech CEOs love to claim they support regulation â€” but, goodness, just not thatÂ regulation. The only rules theyâ€™re happy to take are the rules they suggest themselves. So it turns out that shiny new tech giants with babyfaced CEOs are much like the old, tarnished platform giants in this regard. But onward to Altmanâ€™s tourâ€¦ So far, OpenAIâ€™s CEOâ€™s dash around European capitals has produced a string of flesh-pressing photo ops with heads of government in Spain, Poland, France and the U.K. Why did Spainâ€™s prime minister, Pedro Sanchez, get to be first on Altmanâ€™s charm offensive/hit list? The salient detail here is the Southern European nation takes up the rotating six-month presidency of the European Council this summer, which will give it a lot of leeway to shape discussions at a crucial time in negotiations over the blocâ€™s AI rulebook. Spain has alsoÂ said itâ€™s eager to get the file over the line during its tenure. Alongside this high profile flesh-pressing parade, Altman has been sounding off in public and his tour has duly generated a bunch of headlines warning that OpenAI could shut up shop in the region because of European regulation. So, er, nil points for subtlety. Hereâ€™s the first bit, in tweet digest formâ€¦ Me he reunido con Sam Altman @sama, cofundador de @OpenAI, con quien he compartido que la Inteligencia Artificial es una enorme oportunidad para modernizar nuestras sociedades. Pero es imprescindible que su desarrollo respete los derechos y los valores democrÃ¡ticos. pic.twitter.com/o2jBlNMYRt â€” Pedro SÃ¡nchez (@sanchezcastejon) May 22, 2023  ğŸ¤–Premier @MorawieckiM spotkaÅ‚ siÄ™ z prezesem @OpenAI @sama oraz jego wspÃ³Å‚pracownikami. W zespole @OpenAI waÅ¼nÄ… rolÄ™ odgrywajÄ… Polacy ğŸ‡µğŸ‡± GÅ‚Ã³wnymi tematami rozmÃ³w byÅ‚y m. in: â¡ï¸ rozwÃ³j sztucznej inteligencji oraz moÅ¼liwoÅ›ci udziaÅ‚u polskich firm w tym procesie,â¡ï¸ wpÅ‚ywâ€¦ pic.twitter.com/ai3ZPnudmp â€” Piotr MÃ¼ller (@PiotrMuller) May 23, 2023  Developing talents and technologies in France, acting for regulation at the French, European and global levels, these are our priorities in terms of artificial intelligence. We discussed this with Sam Altman, the creator of ChatGPT. pic.twitter.com/GES0hWv9SY â€” Emmanuel Macron (@EmmanuelMacron) May 23, 2023  Done safely and securely, AI has the potential to be transformational and grow the economy. This evening I met with @sama, @demishassabis and @AnthropicAI's Dario Amodei to discuss how the UK can provide international leadership on AI. pic.twitter.com/8x8NfCbCbG â€” Rishi Sunak (@RishiSunak) May 24, 2023  Tech watchers may recall similar such whistlestop tours in recent years, undertaken by Metaâ€™s Mark Zuckerberg and Googleâ€™s Sundar Pichai, as last seasonâ€™s tech giants sought to lobby heads of government on major pieces of EU digital policy, such as the Digital Services Act and Digital Markets Act. So OpenAI is reaching for the familiar Big Tech playbook here. Albeit itâ€™s repeating the EU lobbying pattern on whatâ€™s â€” apparently â€” a relatively shoestring budget* vs the multiple millions of dollars tech giants like Google and Meta routinely spend annually on lobbying Brussels. Altman also appears to have gone for a bit of a two track approach. As well as schmoozing regional heads of government who â€” in the case of France, Poland and Spain â€” have influence over the final shape of the EUâ€™s AI rulebook via the European Council, heâ€™s been lobbying loudly in public too: Taking part in a discussion event at University College London where he used an on-stage interview to discuss his preference for regulation that was â€œsomething between the traditional European approach and the traditional U.S. approachâ€, per a write up in Time. He also spilled more feels to attendant members of the press, telling TimeÂ and Reuters that his company might just stop operating in Europe if it could not comply with incoming rules for AI. â€œWeâ€™re gonna try to comply,â€ Time reported Altman telling it. But he griped he had â€œa lotâ€ of criticisms of the wording of the EU AI Act â€” which presumably means heâ€™s unhappy with amendments recently proposed by lawmakers in the European Parliament. Earlier this month, Members of the European Parliament on two key committees backed a series of amendments to the Commissionâ€™s original (April 2021) proposal for a risk-based framework for regulating AI that aim to ensure general purpose AI, foundational models and generative AI do not fall outside the rules. As we reported at the time, MEPs backed obligations on providers of foundational models to apply safety checks, data governance measures and risk mitigations prior to putting their models on the market â€” including obligating them to consider â€œforeseeable risks to health, safety, fundamental rights, the environment and democracy and the rule of lawâ€. The amendments would also commit foundational model makers to reduce energy consumption and resource use of their systems and register them in an EU database that will be established by the regulation. While providers of generative AI technologies (such as OpenAIâ€™s ChatGPT) would get transparency obligations â€” meaning they must ensure users are informed content is machine generated; apply â€œadequate safeguardsâ€ in relation to content their systems generate; and provide a summary of any copyrighted materials used to train their AIs. So Altman appears to be taking issue with all that. (Weâ€™ve reached out to OpenAI about its position on the EU AI Act and will update this report with any response.) EU lawmakers back transparency and safety rules for generative AI  In further remarks to Reuters, Altman also said: â€œThe current draft of the EU AI Act would be over-regulating but we have heard itâ€™s going to get pulled backâ€ â€” which, again, appears to be a reference to the parliamentâ€™s proposed amendments. And sounds like an attempt to lobby the Council, a body composed of representatives of EU Member Statesâ€™ governments, to push back in the upcoming trilogue discussions with MEPs in order that the amendments â€œget pulled backâ€. I mean, itâ€™s a safe bet that Altman was repeating his concerns about EU â€œover-regulationâ€ to Spainâ€™s prime minister Pedro Sanchez, Polandâ€™s prime minister Mateusz Jakub Morawieck and Franceâ€™s president Emmanuel Macron in his facetime with them this week. Helpfully, Polandâ€™s governmentâ€™s tweet to mark the visit confirms that â€œissues related to legal regulations regarding the use of AIâ€ were on the discussion agenda in Warsaw â€” alongside talk of â€œopportunities for Polish companies to participateâ€ in the development of AIâ€¦ (So, er, quid pro quo guys! Do you want those OpenAI AI engineer jobs or not?!) Given the timing of Altmanâ€™s trip to Europe, OpenAI may also have its eye on a plenary vote in parliament which is expected early next month â€” a step that will confirm MEPsâ€™ negotiating mandate with the Council on the AI Act file. It may therefore be hoping its lobbying of heads of governments will translate into pressure on certain political factions in the parliament to vote against the amendments backed by the two key committees. This, friends, is how the EU legislative sausage gets made! great meetings today in warsaw, paris, and london. andâ€¦since i was out of the US, i finally got signed up for worldcoin! pic.twitter.com/VUouPyYDpa â€” Sam Altman (@sama) May 23, 2023  Altmanâ€™s tour probably wonâ€™t end here either. Weâ€™re told the EUâ€™s internal market commissioner, Thierry Breton, is expecting to meet with Altman in the coming weeks. But why is OpenAIâ€™s CEO taking time out from his eyeball-taxing tour of EU Member State government bigwigs to meet with U.K. prime minister, Rishi Sunak â€” in a meeting that took place alongside execs at a couple of AI rivals (Google-DeepMindâ€™s Demis Hassabis and Anthropicâ€™s Dario Amodei)? The U.K. does of course remain a major economy in Europe. Plus there have been some rumors OpenAI has been considering setting up a local HQ in the country. While Anthropic has just announced its own London office.Â But â€” on the regulatory side at least â€” it is no longer a member of the EU, which means it has no lawmakers in Brussels who can shape the EUâ€™s AI Act. So itâ€™s a relative minnow in AI rule-making terms. Add to that, Sunakâ€™s government has signalled itâ€™s not planning any new domestic legislation to regulate AI. A recent government white paper laid out in its preferred approach of relying upon existing regulatory bodies, such as the competition authority and privacy watchdog, to provide guidance on safe development of AI â€” rather than legislating bespoke guardrails to regulate uses of the technology. So this meeting is certainly the odd one out for Altman. Also because he was not the only AI CEO in the room. Sunakâ€™s tweet about the meeting offers only a self-serving observation that discussions focused on â€œhow the UK can provide international leadership on AIâ€. (Weâ€™ve reached out to Number 10 Downing Street with questions and will update this report with any response.) DeepMindâ€™s Hassabis also tweeted about having a â€œgood conversationâ€ on â€œdeveloping AI responsiblyâ€, before offering the usual technosolutionist promo claim that: â€œAI has the potential to improve life dramatically, transform industries, deliver scientific and medical breakthroughs if government and industry work together.â€ (Asked about the meeting, Google declined public comment but in background remarks it suggested the participants shared a strong conviction on the promise of AI and important challenges that will require international action, adding that it expects more dialogue as things move forward.) Sunakâ€™s meeting with AI CEOs may offer a hint of a third strategic track for these tech exesâ€™ lobbying of governments and regulators â€” one thatâ€™s focused on trying to defer and dazzle lawmakers with talk of flashy potential and big future fears, while pandering to political self interest (local jobs!) and provincial self importance. The goal is to reframe what responsible AI development means â€” by zooming attention out, not in â€” onto talk of achieving consensus on some broad-brush international principles/standards, rather than having lots of prescriptive local rules. And doing that at the same time as distracting lawmakers (and the media) with talk of â€œsuperintelligentâ€ AIs that donâ€™t actually exist. (To wit: Timeâ€™s report of Altmanâ€™s London talk covers a â€œhandfulâ€ of protestors who are photographed holding signs outside the venue apparently protesting such hypothetical superintelligence.) So the strategy is really about drawing lawmakersâ€™ attention away from harms that already exist and are demonstrably flowing from use of current AI systems â€” whether thatâ€™s mass copyright infringement, supercharged disinformation, systematic privacy abuse, speech and safety issues or indeed economic concerns related to the impact of generative automation on all sorts of jobs â€” with specious talk of existential risks to human civilization posed by non-existent AGI (artificial general intelligence) so that regulators expend their (limited) bandwidth chasing AI ghosts. Earlier this week, OpenAI published a blog post entitled â€œGovernance of superintelligenceâ€ in which current gen AI risks (i.e. the ones which do actually exist) were framed as a secondary concern â€” whereas the company pressed for the spotlight to be trained on risks that are entirely theoretical, writing: â€œWe must mitigate the risks of todayâ€™s AI technology too but superintelligence will require special treatment and coordination.â€ Itâ€™s notable that across tens of blog posts OpenAI has penned over the years it hasnâ€™t found time to write an equivalent post setting out how it thinks (actual) AI should be governed. (The closest itâ€™s come are a blog post from last June, about â€œbest practicesâ€ for deploying large language models, which talks about a â€œpreliminary set of best practicesâ€ to â€œmitigate unintentional harmâ€ and â€œprohibit misuseâ€; and a blog post from last month on â€œsafetyâ€ which was published in response to a regulator intervention in the EU â€” after Italyâ€™s data protection watchdog ordered the service suspended over a raft of suspended infringements of the General Data Protection Regulation.) While, asked by a U.S. senate committee earlier this month to take a stab at defining how AI should be regulated, Altman offered compute power or model capability as one way lawmakers might draw a line for where AI systems should be licensed. But his overall remarks suggested a view â€” far from all the headlines which duly reported him calling for regulation â€” that most AI systems should get a carve out from the rules. â€œI think there are very different levels here,â€ he suggested. â€œAnd I think itâ€™s important that any new approach, any new law does not stop the innovation from happening.â€ The problem for Altman and other AI CEOs in the room who want the kind of general free licence that existed for social media firms when they were scaling into platform giants without prescriptive rules cramping their style, is that the EU is far ahead down the path of regulating AI â€” and doing so in a way that looks set to bring in far more specific rules for existing technologies than the tech bros are comfortable with. Add to that, if Brussels gets its risk-based AI framework in place first, it could end up setting the defacto rulebook for the rest of the world on AI. And Altman at least looks keen to avoid the fabled â€œBrussels effectâ€ setting the tone at his AI party. So in meeting Sunak, most likely, the OpenAI CEO is seeking to drive a bigger wedge between the U.K. and the EU on AI regulation â€” by encouraging the former towards support for some less prescriptive (fuzzier) international standards which can be scoped by the AI companies themselves. As such, the meeting may also represent a third strand of how the company is trying to apply pressure on EU lawmakers at a key point in the blocâ€™s co-legislative process. Since, if one major European economy (the UK) is seen to be taking a different direction and backing looser international â€˜standardsâ€™ vs specific rules, it might cause EU lawmakers to have second thoughts and doubt the full-frame approach before the file is sealed. (And as they say in Brussels, nothing is decided until everything is decided. So thereâ€™s plenty still to play for.) If this is indeed his game, Altman should be aware that EU lawmakers are a wily lot. Nor do they let the grass grow on their patch. So of course the blocâ€™s leaders have already involved themselves in international standards-making for AI â€” including announcing, earlier this week, an initiative joined by Google, to create an â€œAI Pactâ€ to act as a stop-gap before the full-fat AI rules come in. The EUâ€™s digital strategy chief, Margrethe Vestager, has also pressed for G7 nations to back internationally agreed guardrails, seemingly with some success â€” in light of theÂ leaders agreeing last weekend to launch the â€œHiroshima AI Processâ€ and work towards devising AI guardrails, including for generative AI. They also called for the development and adoption of technical standards to keep artificial intelligence â€œtrustworthyâ€ (a choice of term that explicitly echoes the EUâ€™s long-standing language on regulating AI). So, well, expect any future meeting between Altman and the European Commission to entail Brussels urging OpenAIâ€™s CEO to commit the company to a set of international standards the bloc is already involving itself in shaping. Update: In the last few hours commissioner Breton has weighed in publicly on Altmanâ€™s big European tour â€” by tweeting a little warning of his own. â€œThere is no point in attempting blackmail,â€ the EUâ€™s internal market commissioner wrote, hitting out at OpenAIâ€™s suggestion that â€œcrafting a clear framework Europe is holding up the rollout of generative AIâ€. â€œTo the contrary! With the â€˜AI Pactâ€™ I proposed, we aim to assist companies in their preparation to EU AI Act.â€ There is no point in attempting blackmail â€” claiming that by crafting a clear framework, Europe is holding up the rollout of generative #AI. To the contrary! With the â€œAI Pactâ€ I proposed, we aim to assist companies in their preparation to EU AI Act ğŸ‡ªğŸ‡ºhttps://t.co/gHsV69L81S pic.twitter.com/N5r83yWtIe â€” Thierry Breton (@ThierryBreton) May 25, 2023  Update 2: Following Bretonâ€™s shot across the bows, Altman has tweeted to withdraw the threat to leave Europe â€” writing: â€œVery productive week of conversation in Europe about how best to regulate AI! We are exited to continue to operate here and of course have no plans to leave.â€ very productive week of conversations in europe about how to best regulate AI! we are excited to continue to operate here and of course have no plans to leave. â€” Sam Altman (@sama) May 26, 2023  Google to work with Europe on stop-gap â€˜AI Pactâ€™  *Per OpenAIâ€™s entry in the European Transparency Register, where it has only been a registered lobbyist of the EU since June last year, it has allocated a tiny budget to push its positions in Brussels â€” disclosing an annual spend on EU lobbying activities of just â‚¬10,000-â‚¬24,999. Which pales in comparison beside the multiple-millions-apiece routinely spent by the likes of Google and Meta on trying to bend EU lawmakers to their will, per lobby watchers analysis of annual spend. OpenAIâ€™s entry in the register also states that it has so far only lobbied on the AI Act â€” further stipulating: To date, we have met with Washington-based and Brussels-based EU representatives. We have hosted one roundtable with 20 EU diplomats to date and visited 3 embassies. We have also engaged EU representatives in Brussels from time to time starting last summer. (Note: The EU transparency register is not the place where OpenAIâ€™s heads-of-government focused charm offensive would likely be recorded â€” EU lobby watchers routinely criticize an ongoing lack of transparency vis-Ã -vis lobbying thatâ€™s directed at EU Member States and their delegations.) OpenAI leaders propose international regulatory body for AI  