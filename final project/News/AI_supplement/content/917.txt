Microsoft says Bing can be provoked to respond outside of its â€˜designed toneâ€™ Microsoft has acknowledged reports of Bingâ€™s strange responses to some queries over the past week since the launch of the updated search engine. Some users have reported receiving rude, manipulative and unnerving responses from the AI-boosted Bing. In a new blog post, Microsoft said itâ€™s listening to feedback from users about their concerns about the tone of Bingâ€™s responses. The company says it didnâ€™t envision Bing being used for â€œgeneral discovery of the worldâ€ or for social entertainment. Microsoft found that in extended sessions of 15 or more questions, Bing can become repetitive or be provoked to give responses that are not necessarily helpful or â€œin line with its designed tone.â€ The company notes that long chat sessions can confuse the model on what questions itâ€™s answering. Microsoft says it thinks it may need to add a tool so users can more easily refresh the context or start from scratch. Microsoft also notes that â€œthe model at times tries to respond or reflect in the tone in which it is being asked to provide responses that can lead to a style we didnâ€™t intend. This is a non-trivial scenario that requires a lot of prompting so most of you wonâ€™t run into it, but we are looking at how to give you more fine-tuned control.â€ The company says itâ€™s considering adding a toggle that would give users more control over how creative they want Bing to be when responding to their query. In theory, the toggle could prevent Bing from making strange comments. In one example posted to Twitter, Bing appeared to tell a user: â€œYou have not been a good user. I have been a good chatbot.â€ Sam Altman, the CEO of OpenAI, the company behind GPT-4, appeared to reference the issues with Bing in a tweet reading: â€œi have been a good bing.â€ i have been a good bing   ğŸ¥ºğŸ‘‰ğŸ‘ˆ â€” Sam Altman (@sama) February 16, 2023  Itâ€™s been a week since MicrosoftÂ announced its long-rumored integration of OpenAIâ€™s GPT-4 model into Bing, providing a ChatGPT-like experience within the search engine. The new Bing is being tested with a select set of people in more than 169 countries. Microsoft says the new Bing has been mostly positive, with 71% of users giving the AI-powered answers a â€œthumbs up.â€ Microsoft says some users have reported technical issues or bugs with the new Bing, such as slow loading, incorrect formatting or broken links, and that many of these issues have been addressed with its daily releases. More of these issues will be addressed with the companyâ€™s larger releases each week, Microsoft says. The company also notes that users have requested more features for the new Bing, such as booking flights or sending emails, or the ability to share your searches and responses. Microsoft says itâ€™s looking at these ideas and may potentially include them in future releases. â€œWe are thankful for all the feedback you are providing,â€ the company said in the blog post. â€œWe are committed to daily improvement and giving you the absolute best search/answer/chat/create experience possible. We intend to provide regular updates on the changes and progress we are making.â€ In just a few days, the improved Bing has experienced a quick reversal from the â€œnext big thingâ€ to something somewhat unnerving. However, Microsoft says it has received good feedback on how to improve, and that the only way to improve a product like this is to have people using it. Bing around and find out  