Google created an AI that can generate music from text descriptions, but wonâ€™t release it An impressive new AI system from Google can generate music in any genre given a text description. But the company, fearing the risks, has no immediate plans to release it. Called MusicLM, Googleâ€™s certainly isnâ€™t the first generative artificial intelligence system for song. There have been other attempts, including Riffusion, an AI that composes music by visualizing it, as well as Dance Diffusion, Googleâ€™s own AudioML and OpenAIâ€™s Jukebox. But owing to technical limitations and limited training data, none have been able to produce songs particularly complex in composition or high-fidelity. MusicLM is perhaps the first that can. whoa, this is bigger than ChatGPT to me. google almost solved music generation, i'd say. https://t.co/s9PQaJ5R6A â€” Keunwoo Choi (@keunwoochoi) January 27, 2023  Detailed in an academic paper, MusicLM was trained on a dataset of 280,000 hours of music to learn to generate coherent songs for descriptions of â€” as the creators put it â€” â€œsignificant complexityâ€ (e.g. â€œenchanting jazz song with a memorable saxophone solo and a solo singerâ€ or â€œBerlin â€™90s techno with a low bass and strong kick.â€ Its songs, remarkably, sound something like a human artist might compose, albeit not necessarily as inventive or musically cohesive. Itâ€™s hard to overstate just how good the samples sound, given that there arenâ€™t musicians or instrumentalists in the loop. Even when fed somewhat long and meandering descriptions, MusicLM manages to capture nuances like instrumental riffs, melodies and moods. The caption for the sample below, for example, included the bit â€œinduces the experience of being lost in space,â€ and it definitely delivers on that front (at least to my ears): https://techcrunch.com/wp-content/uploads/2023/01/audio-1.wav Hereâ€™s another sample, generated from a description starting with the sentence â€œThe main soundtrack of an arcade game.â€ Plausible, right? https://techcrunch.com/wp-content/uploads/2023/01/audio.wav MusicLMâ€™s artificial intelligence capabilities extend beyond generating short clips of songs. The Google researchers show that the system can build on existing melodies, whether hummed, sung, whistled or played on an instrument. Moreover, MusicLM can take several descriptions written in sequence (e.g. â€œtime to meditate,â€ â€œtime to wake up,â€ â€œtime to run,â€ â€œtime to give 100%â€) and create a sort of melodic â€œstoryâ€ or narrative ranging up to several minutes in length â€” perfectly fit for a movie soundtrack. See below, which came from the sequence â€œelectronic song played in a videogame,â€ â€œmeditation song played next to a river,â€ â€œfire,â€ â€œfireworks.â€ https://techcrunch.com/wp-content/uploads/2023/01/example_2.wav Thatâ€™s not all.Â MusicLM can also be instructed via a combination of picture and caption, or generate audio thatâ€™s â€œplayedâ€ by a specific type of instrument in a certain genre. Even the experience level of the AI â€œmusicianâ€ can be set, and the system can create music inspired by places, epochs or requirements (e.g. motivational music for workouts). But MusicLM isnâ€™t flawless â€” far from it, truthfully. Some of the samples have a distorted quality to them, an unavoidable side effect of the training process. And while MusicLM can technically generate vocals, including choral harmonies, they leave a lot to be desired. Most of the â€œlyricsâ€ range from barely English to pure gibberish, sung by synthesized voices that sound like amalgamations of several artists. Yesterday, Google published a paper on a new AI model called MusicLM. The model generates 24 kHz music from rich captions like "A fusion of reggaeton and electronic dance music, with a spacey, otherworldly sound. Induces the experience of being lost in space." pic.twitter.com/XPv0PEQbUh â€” Product Hunt ğŸ˜¸ (@ProductHunt) January 27, 2023  Still, the Google researchers note the many ethical challenges posed by a system like MusicLM, including a tendency to incorporate copyrighted material from training data into the generated songs. During an experiment, they found that about 1% of the music the system generated was directly replicated from the songs on which it trained â€” a threshold apparently high enough to discourage them from releasing MusicLM in its current state. â€œWe acknowledge the risk of potential misappropriation of creative content associated to the use case,â€ the co-authors of the paper wrote. â€œWe strongly emphasize the need for more future work in tackling these risks associated to music generation.â€ Assuming MusicLM or a system like it is one day made available, it seems inevitable that major legal issues will come to the fore â€” even if the systems are positioned as tools to assist artists rather than replace them. They already have, albeit around simpler AI systems. In 2020, Jay-Zâ€™s record label filed copyright strikes against a YouTube channel, Vocal Synthesis, for using AI to create Jay-Z covers of songs like Billy Joelâ€™s â€œWe Didnâ€™t Start the Fire.â€ After initially removing the videos, YouTube reinstated them, finding the takedown requests were â€œincomplete.â€ But deepfakedÂ music still stands on murky legal ground. "MusicLM: Generating Music from Text"https://t.co/XG1FyPNd4S Impressed to see the quality of autogenerated vocals has gone way up! Sounds real but in a foreign language. pic.twitter.com/4U32ttoexI â€” Jay Hack (@mathemagic1an) January 27, 2023  A whitepaper authored by Eric Sunray, now a legal intern at the Music Publishers Association, argues that AI music generators like MusicLM violate music copyright by creating â€œtapestries of coherent audio from the works they ingest in training, thereby infringing the United States Copyright Actâ€™s reproduction right.â€ Following the release of Jukebox, critics have also questioned whether training AI models on copyrighted musical material constitutes fair use. Similar concerns have been raised around the training data used in image-, code- and text-generating AI systems, which is often scraped from the web without creatorsâ€™ knowledge. From a user perspective, Waxyâ€™s Andy Baio speculates that music generated by an AI system would be considered a derivative work, in which case only the original elements would be protected by copyright. Of course, itâ€™s unclear what might be considered â€œoriginalâ€ in such music; using this music commercially is to enter uncharted waters. Itâ€™s a simpler matter if generated music is used for purposes protected under fair use, like parody and commentary, but Baio expects that courts would have to make case-by-base judgments. It might not be long before thereâ€™s some clarity on the matter. Several lawsuits making their way through the courts will likely have a bearing on music-generating AI, including one pertaining to the rights of artists whose work is used to train artificial intelligence systems without their knowledge or consent. But time will tell. 