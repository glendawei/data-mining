After inking its OpenAI deal, Shutterstock rolls out a generative AI toolkit to create images based on text prompts When Shutterstock and OpenAI announced a partnership to help develop OpenAI’s Dall-E 2 artificial intelligence image-generating platform with Shutterstock libraries to train and feed the algorithm, the stock photo and media giant also hinted that it would soon be bringing its own generative AI tools to users. Today the company took the wraps off that product. Customers of Shutterstock’s Creative Flow online design platform will now be able to create images based on text prompts, powered by OpenAI and Dall-E 2. Key to the feature — which does not appear to have a brand name as such — is that Shutterstock says the images are “ready for licensing” right after they’re made. This is significant given that one of Shutterstock’s big competitors, Getty Images, is currently embroiled in a lawsuit against Stability AI — maker of another generative AI service called Stable Diffusion — over using its images to train its AI without permission from Getty or rightsholders. In other words, Shutterstock’s service is not only embracing the ability to use AI, rather than the skills of a human photographer, to build the image you want to discover, but it’s setting the company up in opposition to Getty in terms of how it is embracing the brave new world of artificial intelligence. Stability AI has been backed with significant funding, but as of yesterday, not as much as OpenAI, which closed a massive, $10 billion round and extended partnership with Microsoft. In addition to Shutterstock’s work with OpenAI, the company earlier this month also announced an expanded deal with Facebook, Instagram and WhatsApp parent Meta, which will be (similar to OpenAI) using Shutterstock’s photo and other media libraries (it also has video and music) to build its AI datasets and to train its algorithms. You can expect more generative AI tools to be rolling out as a result. What’s interesting is that while we don’t know the financial terms of those deals with OpenAI, Meta or another partner, LG, there is a clear commercial end point with these services. Shutterstock’s bet seems to be that it’s worth jumping in and getting involved with these new technologies, and try to build a business around them, rather than stand by and let itself get cannibalized by those tools. The big question will be whether what Shutterstock offers will have a clear enough differentiation, and unique selling point, from others offering generative AI tools for making images. Yes the licensing is currently one aspect that will be compelling, but longer term, if all are built on the same platform, what will set one apart from the other? In image libraries the idea is that one might simply have a better selection, better pricing, better discovery, and overall better experience, for the paying customer (and for the photographer uploading images). Will those parameters remain the same in the AI world or be obliterated? To be fair, Shutterstock is pitching itself as an “ethical” partner here, with promises of paying out to artists whose images have been used to feed these new services. Again, though, the issue will be whether these payouts be anywhere near the compensation those artists and photographers might have gotten for supplying the images themselves. “Shutterstock has developed strategic partnerships over the past two years with key industry players like OpenAI, Meta, and LG AI Research to fuel their generative AI research efforts, and we are now able to uniquely bring responsibly-produced generative AI capabilities to our own customers,” said Paul Hennessy, Chief Executive Officer at Shutterstock, in a statement today. “Our easy-to-use generative platform will transform the way people tell their stories — you no longer have to be a design expert or have access to a creative team to create exceptional work. Our tools are built on an ethical approach and on a library of assets that represents the diverse world we live in, and we ensure that the artists whose works contributed to the development of these models are recognized and rewarded.” 