Biden to Order ‘Wide Action’ to Limit Risks of Rogue AI Use New order will require developers of AI systems that pose risks to security, the economy, health or safety to share test results, while officials set standards for key chemical, biological, radiological, nuclear, and cyber risks New order will require developers of AI systems that pose risks to security, the economy, health or safety to share test results, while officials set standards for key chemical, biological, radiological, nuclear, and cyber risks  US President Joe Biden is due to sign a “sprawling” executive order on Monday that calls for wide-ranging action on artificial intelligence (AI). The order seeks to protect consumers, workers and minority groups from the risks of AI technology, which has boomed this year, with a flurry of developments across the world that many analysts and tech experts have voiced serious concerns about. The executive order he will unveil is the latest step by the administration to set parameters around AI as it makes rapid gains in capability and popularity in an environment of, so far, limited regulation. AI companies such as OpenAI, Alphabet and Meta Platforms previously agreed voluntarily to commit to watermark AI-generated content to make the technology safer.   The new executive order, which Biden will highlight at an event on Monday, goes further than those commitments. It requires that developers of AI systems that pose risks to US national security, the economy, public health or safety share the results of safety tests with the US government, in line with the Defense Production Act, before they are released to the public. It also directs agencies to set standards for that testing and address related chemical, biological, radiological, nuclear, and cybersecurity risks, according to the White House. To make sure government communications are clear, the Commerce Department will “develop guidance for content authentication and watermarking” for label items that are generated by AI, the White House said in a release about the order. White House Deputy Chief of Staff Bruce Reed called the order, which also delves into privacy, housing discrimination and job displacement, the “strongest set of actions” any government had taken to ensure AI security. “It’s the next step in an aggressive strategy to do everything on all fronts to harness the benefits of AI and mitigate the risks,” he said in a statement. The Group of Seven industrial countries on Monday will agree a code of conduct for companies developing advanced artificial intelligence systems, according to a G7 document. A senior administration official, briefing reporters ahead of the official unveiling of the order, pushed back against criticism that Europe had been more aggressive at regulating AI than the United States has. The official said the executive order had the force of law and the White House believed that legislative action from Congress was also necessary for AI governance.  Biden is calling on Congress in particular to pass legislation on data privacy, the White House said. US officials have warned that AI can heighten the risk of bias and civil rights violations and Biden’s executive order seeks to address that by calling for guidance to landlords, federal benefits programs and federal contractors “to keep AI algorithms from being used to exacerbate discrimination,” the release said. The order also calls for the development of “best practices” to address harms that AI may cause workers, including job displacement, and requires a report on labor market impacts. Vice President Kamala Harris will attend an AI global summit in Britain this week; China is also expected to be represented at the meeting, hosted by British Prime Minister Rishi Sunak. Sunak has said only governments could tackle the risks posed by AI, a technology he said could make it easier to build chemical or biological weapons, spread fear and, in a worse-case scenario, escape human control.  An AI expert for Wired said this is Biden’s first executive order focused solely on artificial intelligence, and follows two by his predecessor Donald Trump. But he noted that “so far, government agencies have a spotty record of complying with the two Trump orders” on investments in AI research and development (in 2019), plus a 2020 executive order and the Advancing American AI Act passed last year that require federal agencies to annually disclose an inventory of algorithms in use. “A Stanford Law School study found a pattern of inconsistent compliance, warning of a national AI ‘capacity gap’,” Khari Johnson wrote. But he said: “If Biden’s new order .. works as intended, it will significantly expand that capacity.”             